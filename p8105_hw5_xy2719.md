p8105_hw5_xy2719
================
Yao
2025-11-11

Load key packages.

``` r
library(tidyverse)
library(broom)
```

## Problem 1

``` r
birthdays = sample(1:365, 5, replace = TRUE)

repeated_bday = length(unique(birthdays)) < 5

repeated_bday
```

    ## [1] FALSE

Write a function.

``` r
bday_sim = function(n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE)

  repeated_bday = length(unique(birthdays)) < n_room

  repeated_bday
  
}

bday_sim(20)
```

    ## [1] FALSE

Run the function 10000 times for each group size between 2 and 50.

``` r
bday_sim_results = 
  expand_grid(
    bdays = 2:50,
    iter = 1:10000
  ) |>
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |>
  group_by(
    bdays
  ) |>
  summarize(
    prob_repeat = mean(result)
  )
```

Make a plot showing the probability.

``` r
problem1_p =
  bday_sim_results |>
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() + 
  geom_line() +
  theme_minimal()

problem1_p
```

![](p8105_hw5_xy2719_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Desciption:

``` r
ggsave("figures/problem1_p.jpg", problem1_p)
```

    ## Saving 7 x 5 in image

## Problem 2

``` r
set.seed(1)

# Write function
sim_ttest = function(n_subj, mu = 0, sigma = 5) {
  
  sim_df = 
    tibble(
      x = rnorm(n = n_subj, mean = mu, sd = sigma)
    )
  
  tt_result = t.test(sim_df$x, mu = 0)
  
  tt_result |> 
    broom::tidy() |> 
    summarize(
      mu_true = mu,
      mu_hat = estimate,
      p_value = p.value
    )
}

# Run simulations
sim_results_df = 
  expand_grid(
    mu_true = 0:6,
    iter = 1:5000
  ) |>
  mutate(
    results = map(mu_true, ~ sim_ttest(n_subj = 30, mu = .x, sigma = 5))
  ) |>
  unnest(results, names_sep = "_")
```

``` r
# Plot showing the proportion of times the null was rejected (the power of the test) vs the true value of μ
alpha = 0.05
power_df =
  sim_results_df |> 
  group_by(mu_true) |>
  summarise(power = mean(results_p_value < alpha), .groups = "drop")

problem2_p1 =
  power_df |>
  ggplot(aes(x = mu_true, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True mean",
    y = "Power",
    title = "Power vs True μ"
  ) +
  theme_minimal()

problem2_p1
```

![](p8105_hw5_xy2719_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

Description: Power increases monotonically with the true effect size μ:
as μ moves farther from 0, the test rejects H₀ more often. At μ = 0
power is ~α (≈0.05), and by μ around 5–6 it approaches 1 given n = 30
and σ = 5.

``` r
ggsave("figures/problem2_p1.jpg", problem2_p1)
```

    ## Saving 7 x 5 in image

``` r
# Average μ overall vs among rejections
avg_all =
  sim_results_df |>
  group_by(mu_true) |> 
  summarise(avg_mu_hat = mean(results_mu_hat), .groups = "drop") |>
  mutate(set = "All samples")

avg_rejects =
  sim_results_df |>
  filter(results_p_value < alpha) |>
  group_by(mu_true) |>
  summarise(avg_mu_hat = mean(results_mu_hat), .groups = "drop") |>
  mutate(set = "Rejected only")

avg_both = bind_rows(avg_all, avg_rejects)

problem2_p2 =
  avg_both |>
  ggplot(aes(x = mu_true, y = avg_mu_hat, color = set)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True mean",
    y = "Average estimate of μ",
    title = "Average μ: overall vs rejections"
  ) +
  theme_minimal()

problem2_p2
```

![](p8105_hw5_xy2719_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

The sample average of μ across all simulations is approximately equal to
the true μ, showing that the estimator is unbiased. However, the average
μ among only those samples where the null was rejected is biased
upward—it tends to overestimate the true effect because significant
results preferentially come from samples with unusually large observed
means.

``` r
ggsave("figures/problem2_p2.jpg", problem2_p2)
```

    ## Saving 7 x 5 in image

## Problem 3
